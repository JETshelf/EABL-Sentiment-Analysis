{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Driven Brand Mastery: EABL's Social Analytics\n",
    "\n",
    "\n",
    "## Business Overview\n",
    "media for brand monitoring to enhance brand perception and customer engagement.\n",
    "East African Breweries Limited (EABL) is a leading Fast-Moving Consumer Goods (FMCG) company operating in the beverage industry.\n",
    "EABL's market footprint extends across East Africa, with a significant presence in countries such as Kenya, Uganda, Tanzania, Rwanda, and South Sudan.\n",
    "With a diverse portfolio of brands such as Tusker Lager, Pilsner Lager, WhiteCap Lager,  Johnnie Walker, Smirnoff, Gilbey's Gin, Richot Brandy, Bond 7 Whiskey and Baileys Irish Cream.\n",
    "As part of its strategic approach, EABL is keen on leveraging social \n",
    "\n",
    "##  Problem Statement\n",
    "EABL recognizes the need to closely monitor and understand the sentiments expressed on social media platforms regarding its brands, products, and marketing initiatives. The company aims to address the following challenges:\n",
    "\n",
    "#### 1. Brand Perception and Engagement: \n",
    "\n",
    "The current state of public sentiment towards EABL on social media is not well-understood, and the company lacks insights to proactively manage and improve its brand perception.\n",
    "\n",
    "#### 2. Marketing Campaign Effectiveness: \n",
    "\n",
    "EABL needs to evaluate the impact of its marketing campaigns and promotions on social media to optimize strategies and refine future campaigns.\n",
    "\n",
    "#### 3. Customer Feedback Analysis: \n",
    "\n",
    "There is a lack of systematic analysis of customer feedback related to product quality, packaging, pricing, and overall satisfaction. EABL aims to utilize this feedback for continuous product improvement and innovation.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "### Main Objectives\n",
    "\n",
    "#### Enhance Brand Perception and Customer Engagement:\n",
    "\n",
    "The main objective of our project is to monitor and analyze social media conversations to understand public sentiment towards EABL brands.\n",
    "Identifying areas for improvement and take proactive measures to enhance overall brand perception.\n",
    "\n",
    "### Specific Objectives\n",
    "\n",
    "#### Brand Sentiment Analysis:\n",
    "\n",
    "Analyze sentiments expressed by consumers regarding EABL products, marketing campaigns, and brand image.\n",
    "\n",
    "Categorize sentiments as positive, negative, or neutral to derive actionable insights.\n",
    "\n",
    "#### Campaign Effectiveness:\n",
    "\n",
    "Evaluate the effectiveness of marketing campaigns and promotions through public reactions on social media.\n",
    "\n",
    "Measure key performance indicators (KPIs) such as engagement rates, reach, and sentiment shift during and after campaigns.\n",
    "\n",
    "#### Customer Feedback Analysis:\n",
    "\n",
    "Capture and analyze customer feedback on specific EABL products.\n",
    "\n",
    "Extract insights on taste, packaging, pricing, and overall satisfaction to guide product development and enhancement.\n",
    "\n",
    "######  Success Criteria\n",
    "\n",
    "The success of this project will be measured by:\n",
    "\n",
    "1. A notable improvement in overall brand sentiment scores over a defined period.\n",
    "\n",
    "2. Positive shifts in sentiment during and after key marketing campaigns.\n",
    "\n",
    "3. Tangible product improvements based on customer feedback.\n",
    "\n",
    "4. Enhanced online visibility and engagement compared to competitors.\n",
    "\n",
    "Stakeholders\n",
    "Marketing Team:\n",
    "\n",
    "Benefit from insights to optimize marketing strategies and refine campaigns.\n",
    "Product Development Team:\n",
    "\n",
    "Utilize feedback for continuous product improvement and innovation.\n",
    "Executive Leadership:\n",
    "\n",
    "Receive regular reports on brand health and public perception for strategic decision-making. Objectives\n",
    "\n",
    "\n",
    "## Stakeholders\n",
    "\n",
    "#### 1. Marketing Team:\n",
    "\n",
    "Benefit from insights to optimize marketing strategies and refine campaigns.\n",
    "\n",
    "#### 2. Product Development Team:\n",
    "\n",
    "Utilize feedback for continuous product improvement and innovation.\n",
    "\n",
    "#### 3. Executive Leadership:\n",
    "\n",
    "Receive regular reports on brand health and public perception for strategic decision-making. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn. feature_extraction. text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn. feature_extraction. text import TfidfTransformer\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn. naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split \n",
    "from matplotlib import cm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn. metrics import classification_report\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download ('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading EABL Twitter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ntscraper in c:\\users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages (from ntscraper) (2.24.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages (from ntscraper) (4.9.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages (from ntscraper) (4.6.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages (from beautifulsoup4->ntscraper) (2.0.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests->ntscraper) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests->ntscraper) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests->ntscraper) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\learn-env\\lib\\site-packages (from requests->ntscraper) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install ntscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|██████████| 30/30 [01:23<00:00,  2.80s/it]\n"
     ]
    }
   ],
   "source": [
    "from ntscraper import Nitter\n",
    "scraper=Nitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ADMIN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "Testing instances: 100%|██████████| 30/30 [01:18<00:00,  2.60s/it]\n"
     ]
    }
   ],
   "source": [
    "from ntscraper import Nitter\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Set up sentiment analyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Create Nitter scraper instance\n",
    "scraper = Nitter()\n",
    "\n",
    "def get_tweets_with_sentiment(name, mode, no):\n",
    "    # Fetch tweets using Nitter scraper\n",
    "    tweets = scraper.get_tweets(name, mode=mode, number=no)\n",
    "    \n",
    "    # Initialize an empty list to store final tweet data\n",
    "    final_tweets = []\n",
    "\n",
    "    # Iterate through the fetched tweets\n",
    "    for tweet in tweets['tweets']:\n",
    "        data = tweet['link'], tweet['text'], tweet['date'], tweet['stats']\n",
    "        final_tweets.append(data)\n",
    "\n",
    "    # Create a DataFrame from the collected tweet data\n",
    "    result_data = pd.DataFrame(final_tweets, columns=['data', 'text', 'stats', 'links'])\n",
    "    \n",
    "    # Analyze sentiment and add a new column\n",
    "    result_data['sentiment'] = result_data['text'].apply(lambda x: analyze_sentiment(x))\n",
    "\n",
    "    return result_data\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    # Get sentiment scores\n",
    "    sentiment_scores = sid.polarity_scores(text)\n",
    "    \n",
    "    # Determine sentiment category based on compound score\n",
    "    if sentiment_scores['compound'] >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif sentiment_scores['compound'] <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-Jan-24 15:48:21 - No instance specified, using random instance https://nitter.ktachibana.party\n",
      "08-Jan-24 15:48:29 - Current stats for EABL: 14 tweets, 0 threads...\n",
      "08-Jan-24 15:48:33 - Current stats for EABL: 32 tweets, 0 threads...\n",
      "08-Jan-24 15:48:38 - Current stats for EABL: 43 tweets, 0 threads...\n",
      "08-Jan-24 15:48:43 - Current stats for EABL: 51 tweets, 0 threads...\n",
      "08-Jan-24 15:48:48 - Current stats for EABL: 55 tweets, 0 threads...\n",
      "08-Jan-24 15:48:53 - Current stats for EABL: 59 tweets, 0 threads...\n",
      "08-Jan-24 15:48:58 - Current stats for EABL: 65 tweets, 0 threads...\n",
      "08-Jan-24 15:49:04 - Current stats for EABL: 80 tweets, 0 threads...\n",
      "08-Jan-24 15:49:08 - Current stats for EABL: 93 tweets, 0 threads...\n",
      "08-Jan-24 15:49:14 - Current stats for EABL: 107 tweets, 0 threads...\n",
      "08-Jan-24 15:49:19 - Current stats for EABL: 120 tweets, 0 threads...\n",
      "08-Jan-24 15:49:23 - Current stats for EABL: 138 tweets, 0 threads...\n",
      "08-Jan-24 15:49:28 - Current stats for EABL: 155 tweets, 0 threads...\n",
      "08-Jan-24 15:49:33 - Current stats for EABL: 162 tweets, 0 threads...\n",
      "08-Jan-24 15:49:38 - Current stats for EABL: 164 tweets, 0 threads...\n",
      "08-Jan-24 15:49:43 - Current stats for EABL: 165 tweets, 0 threads...\n",
      "08-Jan-24 15:49:50 - Current stats for EABL: 180 tweets, 0 threads...\n",
      "08-Jan-24 15:49:55 - Current stats for EABL: 198 tweets, 0 threads...\n",
      "08-Jan-24 15:50:00 - Current stats for EABL: 211 tweets, 0 threads...\n",
      "08-Jan-24 15:50:04 - Current stats for EABL: 227 tweets, 0 threads...\n",
      "08-Jan-24 15:50:09 - Current stats for EABL: 239 tweets, 0 threads...\n",
      "08-Jan-24 15:50:14 - Current stats for EABL: 256 tweets, 0 threads...\n",
      "08-Jan-24 15:50:19 - Current stats for EABL: 271 tweets, 0 threads...\n",
      "08-Jan-24 15:50:24 - Current stats for EABL: 288 tweets, 0 threads...\n",
      "08-Jan-24 15:50:29 - Current stats for EABL: 305 tweets, 0 threads...\n",
      "08-Jan-24 15:50:33 - Current stats for EABL: 320 tweets, 0 threads...\n",
      "08-Jan-24 15:50:38 - Current stats for EABL: 338 tweets, 0 threads...\n",
      "08-Jan-24 15:50:42 - Current stats for EABL: 357 tweets, 0 threads...\n",
      "08-Jan-24 15:50:48 - Current stats for EABL: 377 tweets, 0 threads...\n",
      "08-Jan-24 15:50:53 - Current stats for EABL: 394 tweets, 0 threads...\n",
      "08-Jan-24 15:50:58 - Current stats for EABL: 414 tweets, 0 threads...\n",
      "08-Jan-24 15:51:03 - Current stats for EABL: 432 tweets, 0 threads...\n",
      "08-Jan-24 15:51:07 - Current stats for EABL: 448 tweets, 0 threads...\n",
      "08-Jan-24 15:51:12 - Current stats for EABL: 466 tweets, 0 threads...\n",
      "08-Jan-24 15:51:17 - Current stats for EABL: 480 tweets, 0 threads...\n",
      "08-Jan-24 15:51:21 - Current stats for EABL: 497 tweets, 0 threads...\n",
      "08-Jan-24 15:51:26 - Current stats for EABL: 517 tweets, 0 threads...\n",
      "08-Jan-24 15:51:32 - Current stats for EABL: 536 tweets, 0 threads...\n",
      "08-Jan-24 15:51:36 - Current stats for EABL: 553 tweets, 0 threads...\n",
      "08-Jan-24 15:51:41 - Current stats for EABL: 568 tweets, 0 threads...\n",
      "08-Jan-24 15:51:45 - Current stats for EABL: 586 tweets, 0 threads...\n",
      "08-Jan-24 15:51:49 - Current stats for EABL: 604 tweets, 0 threads...\n",
      "08-Jan-24 15:51:54 - Current stats for EABL: 624 tweets, 0 threads...\n",
      "08-Jan-24 15:51:59 - Current stats for EABL: 644 tweets, 0 threads...\n",
      "08-Jan-24 15:52:05 - Current stats for EABL: 660 tweets, 0 threads...\n",
      "08-Jan-24 15:52:10 - Current stats for EABL: 680 tweets, 0 threads...\n",
      "08-Jan-24 15:52:14 - Current stats for EABL: 699 tweets, 0 threads...\n",
      "08-Jan-24 15:52:19 - Current stats for EABL: 713 tweets, 0 threads...\n",
      "08-Jan-24 15:52:24 - Current stats for EABL: 727 tweets, 0 threads...\n",
      "08-Jan-24 15:52:28 - Current stats for EABL: 746 tweets, 0 threads...\n",
      "08-Jan-24 15:52:33 - Current stats for EABL: 764 tweets, 0 threads...\n",
      "08-Jan-24 15:52:38 - Current stats for EABL: 781 tweets, 0 threads...\n",
      "08-Jan-24 15:52:43 - Current stats for EABL: 800 tweets, 0 threads...\n",
      "08-Jan-24 15:52:48 - Current stats for EABL: 818 tweets, 0 threads...\n",
      "08-Jan-24 15:52:53 - Current stats for EABL: 837 tweets, 0 threads...\n",
      "08-Jan-24 15:52:58 - Current stats for EABL: 856 tweets, 0 threads...\n",
      "08-Jan-24 15:53:03 - Current stats for EABL: 869 tweets, 0 threads...\n",
      "08-Jan-24 15:53:08 - Current stats for EABL: 883 tweets, 0 threads...\n",
      "08-Jan-24 15:53:12 - Current stats for EABL: 900 tweets, 0 threads...\n",
      "08-Jan-24 15:53:17 - Current stats for EABL: 920 tweets, 0 threads...\n",
      "08-Jan-24 15:53:22 - Current stats for EABL: 935 tweets, 0 threads...\n",
      "08-Jan-24 15:53:33 - https://nitter.ktachibana.party unreachable. Trying https://nitter.uni-sonia.com\n",
      "08-Jan-24 15:53:34 - https://nitter.uni-sonia.com unreachable. Trying https://nitter.perennialte.ch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing instances: 100%|██████████| 30/30 [00:00<00:00, 388.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High number of retries detected. Testing all instances...\n",
      "New working instances: \n",
      "08-Jan-24 15:53:35 - All instances are unreachable. Check your request and try again.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# EABL Mentions on tweeter\n",
    "result_data = get_tweets_with_sentiment('EABL', 'term', 10000) # scrapimg EABL  Mentions \n",
    "result_data.to_csv('EABL-tweeter-terms') # saving the scaped data into CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(935, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>text</th>\n",
       "      <th>stats</th>\n",
       "      <th>links</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/HisaApp/status/17442819910...</td>\n",
       "      <td>This week's top stock recommendations 📉 by Fai...</td>\n",
       "      <td>Jan 8, 2024 · 8:56 AM UTC</td>\n",
       "      <td>{'comments': 0, 'retweets': 4, 'quotes': 0, 'l...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/GerttyNjeri/status/1744305...</td>\n",
       "      <td>This week's stock recommendations 📉 in the Ken...</td>\n",
       "      <td>Jan 8, 2024 · 10:30 AM UTC</td>\n",
       "      <td>{'comments': 0, 'retweets': 0, 'quotes': 0, 'l...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/Mollage_/status/1744066467...</td>\n",
       "      <td>😂😂 if I was a decision maker at Coca Cola or E...</td>\n",
       "      <td>Jan 7, 2024 · 6:40 PM UTC</td>\n",
       "      <td>{'comments': 1, 'retweets': 2, 'quotes': 0, 'l...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/FirmbridgeKE/status/174426...</td>\n",
       "      <td>OOH advertising is tried and true. When done r...</td>\n",
       "      <td>Jan 8, 2024 · 8:02 AM UTC</td>\n",
       "      <td>{'comments': 0, 'retweets': 0, 'quotes': 0, 'l...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/FinanciallyInc/status/1740...</td>\n",
       "      <td>This week we are joined by @antony_owich found...</td>\n",
       "      <td>Dec 29, 2023 · 8:45 AM UTC</td>\n",
       "      <td>{'comments': 0, 'retweets': 6, 'quotes': 0, 'l...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  https://twitter.com/HisaApp/status/17442819910...   \n",
       "1  https://twitter.com/GerttyNjeri/status/1744305...   \n",
       "2  https://twitter.com/Mollage_/status/1744066467...   \n",
       "3  https://twitter.com/FirmbridgeKE/status/174426...   \n",
       "4  https://twitter.com/FinanciallyInc/status/1740...   \n",
       "\n",
       "                                                text  \\\n",
       "0  This week's top stock recommendations 📉 by Fai...   \n",
       "1  This week's stock recommendations 📉 in the Ken...   \n",
       "2  😂😂 if I was a decision maker at Coca Cola or E...   \n",
       "3  OOH advertising is tried and true. When done r...   \n",
       "4  This week we are joined by @antony_owich found...   \n",
       "\n",
       "                        stats  \\\n",
       "0   Jan 8, 2024 · 8:56 AM UTC   \n",
       "1  Jan 8, 2024 · 10:30 AM UTC   \n",
       "2   Jan 7, 2024 · 6:40 PM UTC   \n",
       "3   Jan 8, 2024 · 8:02 AM UTC   \n",
       "4  Dec 29, 2023 · 8:45 AM UTC   \n",
       "\n",
       "                                               links sentiment  \n",
       "0  {'comments': 0, 'retweets': 4, 'quotes': 0, 'l...  Positive  \n",
       "1  {'comments': 0, 'retweets': 0, 'quotes': 0, 'l...   Neutral  \n",
       "2  {'comments': 1, 'retweets': 2, 'quotes': 0, 'l...   Neutral  \n",
       "3  {'comments': 0, 'retweets': 0, 'quotes': 0, 'l...  Positive  \n",
       "4  {'comments': 0, 'retweets': 6, 'quotes': 0, 'l...   Neutral  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_term= pd.read_csv('EABL-tweeter-terms',index_col=0)\n",
    "print (df_term.shape)\n",
    "df_term.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Cannot choose from an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-717ebcb892c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# EABL Trending on tweeter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresult_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tweets_with_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'EABL'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'hashtag'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# scrapimg EABL  Trending\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mresult_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'EABL-tweeter-trend'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# saving the scaped data into CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-0988120dca0f>\u001b[0m in \u001b[0;36mget_tweets_with_sentiment\u001b[1;34m(name, mode, no)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_tweets_with_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Fetch tweets using Nitter scraper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscraper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mno\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Initialize an empty list to store final tweet data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ntscraper\\nitter.py\u001b[0m in \u001b[0;36mget_tweets\u001b[1;34m(self, terms, mode, number, since, until, near, language, to, filters, exclude, max_retries, instance)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mterm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mterms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m             return self._search(\n\u001b[0m\u001b[0;32m    896\u001b[0m                 \u001b[0mterm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ntscraper\\nitter.py\u001b[0m in \u001b[0;36m_search\u001b[1;34m(self, term, mode, number, since, until, near, language, to, filters, exclude, max_retries, instance)\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid mode. Use 'term', 'hashtag', or 'user'.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ntscraper\\nitter.py\u001b[0m in \u001b[0;36m_initialize_session\u001b[1;34m(self, instance)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mskip_instance_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No instance specified and instance check skipped\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_instance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m             logging.info(\n\u001b[0;32m     86\u001b[0m                 \u001b[1;34mf\"No instance specified, using random instance {self.instance}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ntscraper\\nitter.py\u001b[0m in \u001b[0;36mget_random_instance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    856\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mURL\u001b[0m \u001b[0mof\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0mNitter\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m         \"\"\"\n\u001b[1;32m--> 858\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworking_instances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m     def get_tweets(\n",
      "\u001b[1;32mc:\\Users\\ADMIN\\anaconda3\\envs\\learn-env\\lib\\random.py\u001b[0m in \u001b[0;36mchoice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot choose from an empty sequence'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
     ]
    }
   ],
   "source": [
    "# EABL Trending on tweeter\n",
    "result_data = get_tweets_with_sentiment('EABL', 'hashtag', 5000) # scrapimg EABL  Trending \n",
    "print(len(result_data))\n",
    "result_data.to_csv('EABL-tweeter-trend') # saving the scaped data into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158\n",
      "                                                data  \\\n",
      "0  https://twitter.com/uNDR_gb/status/17382764666...   \n",
      "1  https://twitter.com/ListingsUs/status/17364434...   \n",
      "2  https://twitter.com/Designtech_afr/status/1736...   \n",
      "3  https://twitter.com/OscarMvuria/status/1735774...   \n",
      "4  https://twitter.com/academybballeng/status/173...   \n",
      "\n",
      "                                                text  \\\n",
      "0  Here Are Your #EABL Mid-Season Top 20 Scoring ...   \n",
      "1  Run a company in the US? - win new biz by gett...   \n",
      "2  12 years strong and they aren't stopping. When...   \n",
      "3  Nimefika home wacha zIshikie home , anyway buy...   \n",
      "4  Oaklands’ Jack Davies is a leader 👊  @bballeng...   \n",
      "\n",
      "                        stats  \\\n",
      "0  Dec 22, 2023 · 7:12 PM UTC   \n",
      "1  Dec 17, 2023 · 5:49 PM UTC   \n",
      "2  Dec 16, 2023 · 4:57 PM UTC   \n",
      "3  Dec 15, 2023 · 9:29 PM UTC   \n",
      "4  Dec 13, 2023 · 5:23 PM UTC   \n",
      "\n",
      "                                               links sentiment  \n",
      "0  {'comments': 0, 'retweets': 3, 'quotes': 0, 'l...  Positive  \n",
      "1  {'comments': 1, 'retweets': 0, 'quotes': 0, 'l...  Positive  \n",
      "2  {'comments': 0, 'retweets': 0, 'quotes': 0, 'l...  Positive  \n",
      "3  {'comments': 0, 'retweets': 0, 'quotes': 0, 'l...   Neutral  \n",
      "4  {'comments': 0, 'retweets': 2, 'quotes': 2, 'l...   Neutral  \n"
     ]
    }
   ],
   "source": [
    "print(len(result_data))\n",
    "print(result_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1162, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>text</th>\n",
       "      <th>stats</th>\n",
       "      <th>links</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/uNDR_gb/status/17382764666...</td>\n",
       "      <td>Here Are Your #EABL Mid-Season Top 20 Scoring ...</td>\n",
       "      <td>Dec 22, 2023 · 7:12 PM UTC</td>\n",
       "      <td>{'comments': 0, 'retweets': 3, 'quotes': 0, 'l...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/ListingsUs/status/17364434...</td>\n",
       "      <td>Run a company in the US? - win new biz by gett...</td>\n",
       "      <td>Dec 17, 2023 · 5:49 PM UTC</td>\n",
       "      <td>{'comments': 1, 'retweets': 0, 'quotes': 0, 'l...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/Designtech_afr/status/1736...</td>\n",
       "      <td>12 years strong and they aren't stopping. When...</td>\n",
       "      <td>Dec 16, 2023 · 4:57 PM UTC</td>\n",
       "      <td>{'comments': 0, 'retweets': 0, 'quotes': 0, 'l...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/OscarMvuria/status/1735774...</td>\n",
       "      <td>Nimefika home wacha zIshikie home , anyway buy...</td>\n",
       "      <td>Dec 15, 2023 · 9:29 PM UTC</td>\n",
       "      <td>{'comments': 0, 'retweets': 0, 'quotes': 0, 'l...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/academybballeng/status/173...</td>\n",
       "      <td>Oaklands’ Jack Davies is a leader 👊  @bballeng...</td>\n",
       "      <td>Dec 13, 2023 · 5:23 PM UTC</td>\n",
       "      <td>{'comments': 0, 'retweets': 2, 'quotes': 2, 'l...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  https://twitter.com/uNDR_gb/status/17382764666...   \n",
       "1  https://twitter.com/ListingsUs/status/17364434...   \n",
       "2  https://twitter.com/Designtech_afr/status/1736...   \n",
       "3  https://twitter.com/OscarMvuria/status/1735774...   \n",
       "4  https://twitter.com/academybballeng/status/173...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Here Are Your #EABL Mid-Season Top 20 Scoring ...   \n",
       "1  Run a company in the US? - win new biz by gett...   \n",
       "2  12 years strong and they aren't stopping. When...   \n",
       "3  Nimefika home wacha zIshikie home , anyway buy...   \n",
       "4  Oaklands’ Jack Davies is a leader 👊  @bballeng...   \n",
       "\n",
       "                        stats  \\\n",
       "0  Dec 22, 2023 · 7:12 PM UTC   \n",
       "1  Dec 17, 2023 · 5:49 PM UTC   \n",
       "2  Dec 16, 2023 · 4:57 PM UTC   \n",
       "3  Dec 15, 2023 · 9:29 PM UTC   \n",
       "4  Dec 13, 2023 · 5:23 PM UTC   \n",
       "\n",
       "                                               links sentiment  \n",
       "0  {'comments': 0, 'retweets': 3, 'quotes': 0, 'l...  Positive  \n",
       "1  {'comments': 1, 'retweets': 0, 'quotes': 0, 'l...  Positive  \n",
       "2  {'comments': 0, 'retweets': 0, 'quotes': 0, 'l...  Positive  \n",
       "3  {'comments': 0, 'retweets': 0, 'quotes': 0, 'l...   Neutral  \n",
       "4  {'comments': 0, 'retweets': 2, 'quotes': 2, 'l...   Neutral  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trend= pd.read_csv('EABL-tweeter-trend', index_col=0)\n",
    "\n",
    "print (df_trend.shape)\n",
    "df_trend.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11162, 5)\n"
     ]
    }
   ],
   "source": [
    "#Combine the two DataFrames\n",
    "combined_df = pd.concat([df_term, df_trend], ignore_index=True)\n",
    "print(combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-387c84faba20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcombined_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'combined_df' is not defined"
     ]
    }
   ],
   "source": [
    "combined_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "#### 1. Brand Mentions:\n",
    "\n",
    "Social media posts, comments, and mentions related to EABL and its brands.\n",
    "\n",
    "Data sources: Twitter, Facebook, Instagram (Likes, shares, comments, EABL relevant hashtags.)\n",
    "\n",
    "\n",
    "#### Product Feedback:\n",
    "\n",
    "Comments and discussions regarding specific EABL products.\n",
    "\n",
    "#### Data sources: \n",
    "\n",
    "Social media platforms, review sites, online forums.\n",
    "\n",
    "Data on taste, packaging, pricing, and overall satisfaction.\n",
    "\n",
    "#### Campaign Reactions:\n",
    "\n",
    "Public reactions to EABL's marketing campaigns and promotions.\n",
    "\n",
    "Data sources: Social media platforms.\n",
    "\n",
    "#### Event Participation:\n",
    "\n",
    "Social media mentions related to EABL-sponsored events and promotions.\n",
    "\n",
    "#### Customer Service Interactions:\n",
    "\n",
    "Social media interactions with EABL's official customer service handles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please ensure that the document you submit adheres to the Crisp DM methodology. The Business Understanding section should include a comprehensive business overview, a clear problem statement, main objectives, and specific objectives that are precise and to the point (have at least 3 specific objectives). Additionally, include success criteria for your project.\n",
    "\n",
    "For the Data Understanding section, provide a thorough explanation of the dataset you plan to work on. Be as detailed as possible in all aspects of your pitch.\n",
    "\n",
    "We look forward to receiving your project pitches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
